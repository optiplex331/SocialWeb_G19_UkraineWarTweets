{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Merge CSV Files in Each Event Directory",
   "id": "a08e07eeba77b592"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "import gc"
   ],
   "id": "732d7140ea656f9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_dir = Path('./timeline')  \n",
    "output_dir = Path('./timeline/combined')   \n",
    "\n",
    "event_dirs = [d for d in data_dir.iterdir() if d.is_dir()]\n",
    "\n",
    "print(f\"Discover {len(event_dirs)} event directoryã€‚\")\n",
    "for event in event_dirs:\n",
    "    print(event.name)\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ],
   "id": "ef22f009e09d1ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "columns_to_use = [\n",
    "    \"userid\", \"username\", \"acctdesc\", \"location\", \"following\", \"followers\", \"totaltweets\",\n",
    "    \"usercreatedts\", \"tweetid\", \"tweetcreatedts\", \"retweetcount\", \"text\", \"hashtags\",\n",
    "    \"language\", \"coordinates\", \"favorite_count\", \"is_retweet\",\n",
    "    \"original_tweet_id\", \"original_tweet_userid\", \"original_tweet_username\",\n",
    "    \"in_reply_to_status_id\", \"in_reply_to_user_id\", \"in_reply_to_screen_name\",\n",
    "    \"is_quote_status\", \"quoted_status_id\", \"quoted_status_userid\", \"quoted_status_username\",\n",
    "    \"extractedts\"\n",
    "]\n",
    "\n",
    "for event_dir in event_dirs:\n",
    "    print(f\"\\nProcessing event directory: {event_dir.name}\")\n",
    "    \n",
    "    # Get all CSV files (including gzip-compressed CSVs) in the event directory\n",
    "    csv_files = list(event_dir.glob('*.csv')) + list(event_dir.glob('*.csv.gz'))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"  - No CSV files found in {event_dir.name}\")\n",
    "        continue\n",
    "    \n",
    "    dataframe_collection = []\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            if csv_file.suffix == '.gz':\n",
    "                # Read gzip-compressed CSV file\n",
    "                df = pd.read_csv(\n",
    "                    csv_file,\n",
    "                    compression='gzip',\n",
    "                    encoding='utf-8',\n",
    "                    usecols=columns_to_use,\n",
    "                    engine='python',\n",
    "                    quoting=1  # csv.QUOTE_ALL\n",
    "                )\n",
    "            else:\n",
    "                # Read regular CSV file\n",
    "                df = pd.read_csv(\n",
    "                    csv_file,\n",
    "                    encoding='utf-8',\n",
    "                    usecols=columns_to_use,\n",
    "                    engine='python',\n",
    "                    quoting=1  # csv.QUOTE_ALL\n",
    "                )\n",
    "            \n",
    "            dataframe_collection.append(df)\n",
    "            print(f\"  - Successfully read file: {csv_file.name}, containing {len(df)} tweets.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error reading file {csv_file.name}: {e}\")\n",
    "    \n",
    "    if not dataframe_collection:\n",
    "        print(f\"  - No files were successfully read in {event_dir.name}\")\n",
    "        continue\n",
    "    \n",
    "    # Merge all DataFrames\n",
    "    try:\n",
    "        df_combined = pd.concat(dataframe_collection, axis=0, ignore_index=True)\n",
    "        print(f\"  - Combined DataFrame contains {len(df_combined)} tweets.\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - Error merging DataFrames: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Convert timestamp fields\n",
    "    df_combined['tweetcreatedts'] = pd.to_datetime(df_combined['tweetcreatedts'], errors='coerce')\n",
    "    df_combined['extractedts'] = pd.to_datetime(df_combined['extractedts'], errors='coerce')\n",
    "    \n",
    "    # Sort by 'tweetcreatedts'\n",
    "    df_combined.sort_values(by='tweetcreatedts', inplace=True)\n",
    "    \n",
    "    # Reset index\n",
    "    df_combined.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # Define output file path\n",
    "    # Save as compressed CSV\n",
    "    output_file = output_dir / f\"{event_dir.name}_merged.csv.gz\"  \n",
    "    # Save as uncompressed CSV\n",
    "    # output_file = output_dir / f\"{event_dir.name}_merged.csv\"\n",
    "    \n",
    "    try:\n",
    "        df_combined.to_csv(output_file, index=False, compression='gzip')  # Save with gzip compression\n",
    "        # df_combined.to_csv(output_file, index=False)  # Save without compression\n",
    "        print(f\"  - Successfully saved merged and sorted data to: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - Error saving merged data to {output_file}: {e}\")\n",
    "    \n",
    "    del df_combined\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\nData processing for all events completed.\")"
   ],
   "id": "368ea465ced63cce",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data_env)",
   "language": "python",
   "name": "data_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
