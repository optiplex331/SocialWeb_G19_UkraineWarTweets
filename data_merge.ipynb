{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 俄乌战争虚假信息与谣言传播分析 - 数据准备与抽取\n",
    "\n",
    "## 1. 导入必要的库"
   ],
   "id": "a08e07eeba77b592"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T03:29:39.711040Z",
     "start_time": "2024-12-12T03:29:39.700578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "import gc"
   ],
   "id": "732d7140ea656f9a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. 定义数据路径与事件节点",
   "id": "bce64bd522403614"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T03:47:20.294215Z",
     "start_time": "2024-12-12T03:47:20.210135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义数据目录\n",
    "data_dir = Path('./timeline')  # 修改为实际路径\n",
    "output_dir = Path('./timeline/combined')   # 修改为实际路径\n",
    "\n",
    "# 获取所有事件子目录\n",
    "event_dirs = [d for d in data_dir.iterdir() if d.is_dir()]\n",
    "\n",
    "print(f\"发现 {len(event_dirs)} 个事件目录。\")\n",
    "for event in event_dirs:\n",
    "    print(event.name)\n",
    "\n",
    "# 创建输出目录（如果不存在）\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ],
   "id": "ef22f009e09d1ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "发现 8 个事件目录。\n",
      "20220227-0302\n",
      "20230518-0524\n",
      "20220518-0524\n",
      "20220930-1006\n",
      "20221109-1115\n",
      "20220623-0701\n",
      "20220330-0405\n",
      "20230301-0305\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T04:00:56.954063Z",
     "start_time": "2024-12-12T03:47:37.933988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义需要读取的列\n",
    "columns_to_use = [\n",
    "    \"userid\", \"username\", \"acctdesc\", \"location\", \"following\", \"followers\", \"totaltweets\",\n",
    "    \"usercreatedts\", \"tweetid\", \"tweetcreatedts\", \"retweetcount\", \"text\", \"hashtags\",\n",
    "    \"language\", \"coordinates\", \"favorite_count\", \"is_retweet\",\n",
    "    \"original_tweet_id\", \"original_tweet_userid\", \"original_tweet_username\",\n",
    "    \"in_reply_to_status_id\", \"in_reply_to_user_id\", \"in_reply_to_screen_name\",\n",
    "    \"is_quote_status\", \"quoted_status_id\", \"quoted_status_userid\", \"quoted_status_username\",\n",
    "    \"extractedts\"\n",
    "]\n",
    "\n",
    "for event_dir in event_dirs:\n",
    "    print(f\"\\n处理事件目录: {event_dir.name}\")\n",
    "    \n",
    "    # 获取该事件目录下所有CSV文件（支持gzip压缩的CSV）\n",
    "    csv_files = list(event_dir.glob('*.csv')) + list(event_dir.glob('*.csv.gz'))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"  - 没有找到CSV文件在 {event_dir.name}\")\n",
    "        continue\n",
    "    \n",
    "    dataframe_collection = []\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            if csv_file.suffix == '.gz':\n",
    "                # 读取gzip压缩的CSV文件\n",
    "                df = pd.read_csv(\n",
    "                    csv_file,\n",
    "                    compression='gzip',\n",
    "                    encoding='utf-8',\n",
    "                    usecols=columns_to_use,\n",
    "                    engine='python',\n",
    "                    quoting=1  # csv.QUOTE_ALL\n",
    "                )\n",
    "            else:\n",
    "                # 读取普通的CSV文件\n",
    "                df = pd.read_csv(\n",
    "                    csv_file,\n",
    "                    encoding='utf-8',\n",
    "                    \n",
    "                    engine='python',\n",
    "                    quoting=1  # csv.QUOTE_ALL\n",
    "                )\n",
    "            \n",
    "            dataframe_collection.append(df)\n",
    "            print(f\"  - 成功读取文件: {csv_file.name}，包含 {len(df)} 条推文。\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - 读取文件 {csv_file.name} 时出错: {e}\")\n",
    "    \n",
    "    if not dataframe_collection:\n",
    "        print(f\"  - 没有成功读取任何文件在 {event_dir.name}\")\n",
    "        continue\n",
    "    \n",
    "    # 合并所有DataFrame\n",
    "    try:\n",
    "        df_combined = pd.concat(dataframe_collection, axis=0, ignore_index=True)\n",
    "        print(f\"  - 合并后的DataFrame包含 {len(df_combined)} 条推文。\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - 合并DataFrame时出错: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # 转换时间戳字段\n",
    "    df_combined['tweetcreatedts'] = pd.to_datetime(df_combined['tweetcreatedts'], errors='coerce')\n",
    "    df_combined['extractedts'] = pd.to_datetime(df_combined['extractedts'], errors='coerce')\n",
    "    \n",
    "    \n",
    "        # 按'tweetcreatedts'排序\n",
    "    df_combined.sort_values(by='tweetcreatedts', inplace=True)\n",
    "    \n",
    "    # 重置索引\n",
    "    df_combined.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # 定义输出文件路径\n",
    "    output_file = output_dir / f\"{event_dir.name}_merged.csv.gz\"  # 保存为压缩CSV\n",
    "    # 如果需要保存为未压缩的CSV，可以使用以下行并注释上面一行\n",
    "    # output_file = output_dir / f\"{event_dir.name}_merged.csv\"\n",
    "    \n",
    "    try:\n",
    "        df_combined.to_csv(output_file, index=False, compression='gzip')  # 使用gzip压缩\n",
    "        # df_combined.to_csv(output_file, index=False)  # 未压缩保存\n",
    "        print(f\"  - 成功保存合并并排序的数据到: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - 保存合并数据到 {output_file} 时出错: {e}\")\n",
    "    \n",
    "    # 清理内存\n",
    "    del df_combined\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n所有事件的数据处理完成。\")"
   ],
   "id": "368ea465ced63cce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理事件目录: 20220227-0302\n",
      "  - 成功读取文件: UkraineCombinedTweetsDeduped_FEB28_part2.csv，包含 140384 条推文。\n",
      "  - 成功读取文件: UkraineCombinedTweetsDeduped_FEB28_part1.csv，包含 237787 条推文。\n",
      "  - 成功读取文件: UkraineCombinedTweetsDeduped_FEB27.csv，包含 357018 条推文。\n",
      "  - 成功读取文件: UkraineCombinedTweetsDeduped_MAR01.csv，包含 409279 条推文。\n",
      "  - 成功读取文件: UkraineCombinedTweetsDeduped_MAR02.csv，包含 417031 条推文。\n",
      "  - 合并后的DataFrame包含 1561499 条推文。\n",
      "  - 成功保存合并并排序的数据到: timeline/combined/20220227-0302_merged.csv.gz\n",
      "\n",
      "处理事件目录: 20230518-0524\n",
      "  - 成功读取文件: 20230518_to_20230520_UkraineCombinedTweetsDeduped.csv，包含 132618 条推文。\n",
      "  - 成功读取文件: 20230523_UkraineCombinedTweetsDeduped.csv，包含 26077 条推文。\n",
      "  - 成功读取文件: 20230524_UkraineCombinedTweetsDeduped.csv，包含 21954 条推文。\n",
      "  - 成功读取文件: 20230522_UkraineCombinedTweetsDeduped.csv，包含 39176 条推文。\n",
      "  - 成功读取文件: 20230521_UkraineCombinedTweetsDeduped.csv，包含 52147 条推文。\n",
      "  - 合并后的DataFrame包含 271972 条推文。\n",
      "  - 成功保存合并并排序的数据到: timeline/combined/20230518-0524_merged.csv.gz\n",
      "\n",
      "处理事件目录: 20220518-0524\n",
      "  - 成功读取文件: 0519_UkraineCombinedTweetsDeduped.csv，包含 272231 条推文。\n",
      "  - 成功读取文件: 0522_UkraineCombinedTweetsDeduped.csv，包含 197877 条推文。\n",
      "  - 成功读取文件: 0521_UkraineCombinedTweetsDeduped.csv，包含 211623 条推文。\n",
      "  - 成功读取文件: 0523_UkraineCombinedTweetsDeduped.csv，包含 245001 条推文。\n",
      "  - 成功读取文件: 0518_UkraineCombinedTweetsDeduped.csv，包含 319210 条推文。\n",
      "  - 成功读取文件: 0520_UkraineCombinedTweetsDeduped.csv，包含 229813 条推文。\n",
      "  - 成功读取文件: 0524_UkraineCombinedTweetsDeduped.csv，包含 246600 条推文。\n",
      "  - 合并后的DataFrame包含 1722355 条推文。\n",
      "  - 成功保存合并并排序的数据到: timeline/combined/20220518-0524_merged.csv.gz\n",
      "\n",
      "处理事件目录: 20220930-1006\n",
      "  - 成功读取文件: 1005_UkraineCombinedTweetsDeduped.csv，包含 53903 条推文。\n",
      "  - 成功读取文件: 1001_UkraineCombinedTweetsDeduped.csv，包含 65737 条推文。\n",
      "  - 成功读取文件: 1006_UkraineCombinedTweetsDeduped.csv，包含 55377 条推文。\n",
      "  - 成功读取文件: 1002_UkraineCombinedTweetsDeduped.csv，包含 51155 条推文。\n",
      "  - 成功读取文件: 1004_UkraineCombinedTweetsDeduped.csv，包含 59319 条推文。\n",
      "  - 成功读取文件: 1003_UkraineCombinedTweetsDeduped.csv，包含 60040 条推文。\n",
      "  - 成功读取文件: 0930_UkraineCombinedTweetsDeduped.csv，包含 69930 条推文。\n",
      "  - 合并后的DataFrame包含 415461 条推文。\n",
      "  - 成功保存合并并排序的数据到: timeline/combined/20220930-1006_merged.csv.gz\n",
      "\n",
      "处理事件目录: 20221109-1115\n",
      "  - 成功读取文件: 1115_UkraineCombinedTweetsDeduped.csv，包含 100524 条推文。\n",
      "  - 成功读取文件: 1111_UkraineCombinedTweetsDeduped.csv，包含 60872 条推文。\n",
      "  - 成功读取文件: 1109_UkraineCombinedTweetsDeduped.csv，包含 63623 条推文。\n",
      "  - 成功读取文件: 1112_UkraineCombinedTweetsDeduped.csv，包含 47580 条推文。\n",
      "  - 成功读取文件: 1110_UkraineCombinedTweetsDeduped.csv，包含 50945 条推文。\n",
      "  - 成功读取文件: 1114_UkraineCombinedTweetsDeduped.csv，包含 48955 条推文。\n",
      "  - 成功读取文件: 1113_UkraineCombinedTweetsDeduped.csv，包含 42680 条推文。\n",
      "  - 合并后的DataFrame包含 415179 条推文。\n",
      "  - 成功保存合并并排序的数据到: timeline/combined/20221109-1115_merged.csv.gz\n",
      "\n",
      "处理事件目录: 20220623-0701\n",
      "  - 成功读取文件: 0628_UkraineCombinedTweetsDeduped.csv，包含 284429 条推文。\n",
      "  - 成功读取文件: 0624_UkraineCombinedTweetsDeduped.csv，包含 203939 条推文。\n",
      "  - 成功读取文件: 0623_UkraineCombinedTweetsDeduped.csv，包含 217374 条推文。\n",
      "  - 成功读取文件: 0627_UkraineCombinedTweetsDeduped.csv，包含 271100 条推文。\n",
      "  - 成功读取文件: 0630_UkraineCombinedTweetsDeduped.csv，包含 219794 条推文。\n",
      "  - 成功读取文件: 0625_UkraineCombinedTweetsDeduped.csv，包含 173689 条推文。\n",
      "  - 成功读取文件: 0629_UkraineCombinedTweetsDeduped.csv，包含 282156 条推文。\n",
      "  - 成功读取文件: 0701_UkraineCombinedTweetsDeduped.csv，包含 195178 条推文。\n",
      "  - 成功读取文件: 0626_UkraineCombinedTweetsDeduped.csv，包含 213161 条推文。\n",
      "  - 合并后的DataFrame包含 2060820 条推文。\n",
      "  - 成功保存合并并排序的数据到: timeline/combined/20220623-0701_merged.csv.gz\n",
      "\n",
      "处理事件目录: 20220330-0405\n",
      "  - 成功读取文件: 0401_UkraineCombinedTweetsDeduped.csv，包含 364875 条推文。\n",
      "  - 成功读取文件: UkraineCombinedTweetsDeduped_MAR31.csv，包含 344515 条推文。\n",
      "  - 成功读取文件: 0405_UkraineCombinedTweetsDeduped.csv，包含 452569 条推文。\n",
      "  - 成功读取文件: UkraineCombinedTweetsDeduped_MAR30.csv，包含 348864 条推文。\n",
      "  - 成功读取文件: 0402_UkraineCombinedTweetsDeduped.csv，包含 370977 条推文。\n",
      "  - 成功读取文件: 0404_UkraineCombinedTweetsDeduped.csv，包含 430421 条推文。\n",
      "  - 成功读取文件: 0403_UkraineCombinedTweetsDeduped.csv，包含 445466 条推文。\n",
      "  - 合并后的DataFrame包含 2757687 条推文。\n",
      "  - 成功保存合并并排序的数据到: timeline/combined/20220330-0405_merged.csv.gz\n",
      "\n",
      "处理事件目录: 20230301-0305\n",
      "  - 成功读取文件: 20230303_UkraineCombinedTweetsDeduped.csv，包含 154484 条推文。\n",
      "  - 成功读取文件: 20230304_UkraineCombinedTweetsDeduped.csv，包含 137869 条推文。\n",
      "  - 成功读取文件: 20230302_UkraineCombinedTweetsDeduped.csv，包含 163247 条推文。\n",
      "  - 成功读取文件: 20230305_UkraineCombinedTweetsDeduped.csv，包含 136083 条推文。\n",
      "  - 成功读取文件: 20230301_UkraineCombinedTweetsDeduped.csv，包含 154714 条推文。\n",
      "  - 合并后的DataFrame包含 746397 条推文。\n",
      "  - 成功保存合并并排序的数据到: timeline/combined/20230301-0305_merged.csv.gz\n",
      "\n",
      "所有事件的数据处理完成。\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data_env)",
   "language": "python",
   "name": "data_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
